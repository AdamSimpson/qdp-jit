

.const .align 8 .b8 __cudart_i2opi_d_sin_f64[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.const .align 8 .b8 __cudart_sin_cos_coeffs_sin_f64[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd_sin_f64(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot0[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<48>;
	.reg .s64 	%rd<88>;
	.reg .f64 	%fd<3>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.f64 	%fd1, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd31, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd33, %SPL, 0;
	.loc 2 1799 5
	mov.b64 	%rd2, %fd1;
	.loc 3 271 3
	and.b64  	%rd85, %rd2, -9223372036854775808;
	.loc 3 272 3
	shr.u64 	%rd34, %rd2, 52;
	and.b64  	%rd35, %rd34, 2047;
	add.s64 	%rd36, %rd35, 4294966272;
	cvt.u32.u64 	%r1, %rd36;
	.loc 3 273 3
	shl.b64 	%rd37, %rd2, 11;
	or.b64  	%rd4, %rd37, -9223372036854775808;
	.loc 3 275 3
	shr.u32 	%r10, %r1, 6;
	mov.u32 	%r11, 16;
	.loc 3 275 3
	sub.s32 	%r2, %r11, %r10;
	mov.u32 	%r12, 15;
	.loc 3 278 3
	sub.s32 	%r47, %r12, %r10;
	mov.u32 	%r13, 19;
	.loc 3 278 3
	sub.s32 	%r14, %r13, %r10;
	mov.u32 	%r15, 18;
	.loc 2 210 5
	min.s32 	%r4, %r15, %r14;
	.loc 3 278 3
	setp.ge.s32 	%p1, %r47, %r4;
	mov.u64 	%rd82, 0;
	.loc 3 278 3
	@%p1 bra 	BB0_3;

	cvt.u32.u64 	%r16, %rd34;
	and.b32  	%r17, %r16, 2047;
	.loc 3 279 5
	add.s32 	%r18, %r17, -1024;
	shr.u32 	%r19, %r18, 6;
	add.s32 	%r20, %r19, -15;
	cvt.s64.s32 	%rd40, %r20;
	.loc 3 279 5
	sub.s32 	%r22, %r12, %r19;
	cvt.s64.s32 	%rd41, %r22;
	.loc 3 279 5
	add.s64 	%rd42, %rd40, %rd41;
	shl.b64 	%rd43, %rd42, 3;
	add.s64 	%rd81, %rd33, %rd43;
	.loc 3 278 3
	mul.wide.s32 	%rd44, %r22, 8;
	mov.u64 	%rd45, __cudart_i2opi_d_sin_f64;
	add.s64 	%rd80, %rd45, %rd44;
	mov.u64 	%rd82, 0;

BB0_2:
	.pragma "nounroll";
	.loc 3 279 5
	ld.const.u64 	%rd46, [%rd80];
	.loc 2 287 5
	mul.hi.u64 	%rd47, %rd46, %rd4;
	.loc 3 281 5
	mad.lo.s64 	%rd48, %rd46, %rd4, %rd82;
	setp.lt.u64 	%p2, %rd48, %rd82;
	.loc 3 282 5
	selp.u64 	%rd49, 1, 0, %p2;
	add.s64 	%rd82, %rd49, %rd47;
	.loc 3 283 5
	st.local.u64 	[%rd81], %rd48;
	.loc 3 278 3
	add.s64 	%rd81, %rd81, 8;
	add.s64 	%rd80, %rd80, 8;
	.loc 3 278 40
	add.s32 	%r47, %r47, 1;
	.loc 3 278 3
	setp.lt.s32 	%p3, %r47, %r4;
	@%p3 bra 	BB0_2;

BB0_3:
	mov.u32 	%r25, 1;
	.loc 3 283 5
	sub.s32 	%r26, %r25, %r2;
	.loc 3 285 3
	add.s32 	%r27, %r26, %r47;
	mul.wide.s32 	%rd50, %r27, 8;
	add.s64 	%rd51, %rd33, %rd50;
	st.local.u64 	[%rd51], %rd82;
	.loc 3 290 3
	add.s64 	%rd14, %rd33, 24;
	ld.local.u64 	%rd83, [%rd33+24];
	.loc 3 291 3
	ld.local.u64 	%rd84, [%rd33+16];
	.loc 3 286 3
	and.b32  	%r8, %r1, 63;
	.loc 3 292 3
	setp.eq.s32 	%p4, %r8, 0;
	@%p4 bra 	BB0_5;

	mov.u32 	%r31, 64;
	.loc 3 293 5
	sub.s32 	%r32, %r31, %r8;
	.loc 3 294 5
	shl.b64 	%rd52, %rd83, %r8;
	shr.u64 	%rd53, %rd84, %r32;
	or.b64  	%rd83, %rd53, %rd52;
	.loc 3 295 5
	shl.b64 	%rd54, %rd84, %r8;
	ld.local.u64 	%rd55, [%rd14+-16];
	shr.u64 	%rd56, %rd55, %r32;
	or.b64  	%rd84, %rd56, %rd54;

BB0_5:
	.loc 3 297 3
	shr.u64 	%rd57, %rd83, 62;
	cvt.u32.u64 	%r34, %rd57;
	.loc 3 299 3
	shr.u64 	%rd58, %rd84, 62;
	shl.b64 	%rd59, %rd83, 2;
	or.b64  	%rd87, %rd58, %rd59;
	.loc 3 300 3
	shl.b64 	%rd22, %rd84, 2;
	.loc 3 301 3
	shr.u64 	%rd60, %rd83, 61;
	cvt.u32.u64 	%r35, %rd60;
	and.b32  	%r36, %r35, 1;
	.loc 3 302 3
	add.s32 	%r37, %r36, %r34;
	.loc 3 303 3
	neg.s32 	%r38, %r37;
	setp.eq.s64 	%p5, %rd85, 0;
	selp.b32 	%r39, %r37, %r38, %p5;
	.loc 3 304 3
	st.u32 	[%rd31], %r39;
	.loc 3 305 3
	setp.eq.s32 	%p6, %r36, 0;
	mov.u64 	%rd86, %rd22;
	@%p6 bra 	BB0_7;

	.loc 3 307 5
	not.b64 	%rd61, %rd87;
	.loc 3 308 5
	neg.s64 	%rd23, %rd22;
	.loc 3 309 5
	setp.eq.s64 	%p7, %rd22, 0;
	selp.u64 	%rd62, 1, 0, %p7;
	.loc 3 310 5
	add.s64 	%rd87, %rd62, %rd61;
	.loc 3 311 5
	xor.b64  	%rd85, %rd85, -9223372036854775808;
	mov.u64 	%rd86, %rd23;

BB0_7:
	.loc 2 151 5
	clz.b64 	%r9, %rd87;
	.loc 3 315 3
	setp.eq.s32 	%p8, %r9, 0;
	@%p8 bra 	BB0_9;

	.loc 3 316 5
	shl.b64 	%rd63, %rd87, %r9;
	mov.u32 	%r41, 64;
	.loc 3 316 5
	sub.s32 	%r42, %r41, %r9;
	shr.u64 	%rd64, %rd86, %r42;
	or.b64  	%rd87, %rd64, %rd63;

BB0_9:
	mov.u64 	%rd65, -3958705157555305931;
	.loc 2 287 5
	mul.hi.u64 	%rd66, %rd87, %rd65;
	.loc 3 320 3
	setp.gt.s64 	%p9, %rd66, 0;
	.loc 3 321 5
	shl.b64 	%rd67, %rd66, 1;
	.loc 3 318 3
	mul.lo.s64 	%rd68, %rd87, -3958705157555305931;
	.loc 3 321 5
	shr.u64 	%rd69, %rd68, 63;
	or.b64  	%rd70, %rd67, %rd69;
	.loc 3 320 3
	selp.b64 	%rd71, %rd70, %rd66, %p9;
	selp.b32 	%r43, -1, 0, %p9;
	mov.u32 	%r44, 1022;
	.loc 3 320 3
	sub.s32 	%r45, %r44, %r9;
	.loc 3 324 3
	add.s32 	%r46, %r45, %r43;
	cvt.u64.u32 	%rd72, %r46;
	shl.b64 	%rd73, %rd72, 52;
	add.s64 	%rd74, %rd71, 1;
	shr.u64 	%rd75, %rd74, 10;
	add.s64 	%rd76, %rd75, 1;
	shr.u64 	%rd77, %rd76, 1;
	add.s64 	%rd78, %rd77, %rd73;
	or.b64  	%rd79, %rd78, %rd85;
	.loc 2 1792 5
	mov.b64 	%fd2, %rd79;
	st.param.f64	[func_retval0+0], %fd2;
	.loc 3 326 3
	ret;
}


	.func (.reg .f64 res) func_sin_f64 ( .reg .f64 arg)
{
	.local .align 4 .b8 	__local_depot1[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<6>;
	.reg .s32 	%r<17>;
	.reg .s64 	%rd<10>;
	.reg .f64 	%fd<44>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	mov.f64 	%fd41, arg;
	cvta.to.global.u64 	%rd1, %rd3;
	add.u64 	%rd4, %SP, 0;
	cvta.to.local.u64 	%rd2, %rd4;
	mov.u64 	%rd5, 9218868437227405312;
	.loc 2 1792 5
	mov.b64 	%fd14, %rd5;
	.loc 2 405 5
	abs.f64 	%fd15, %fd41;
	.loc 3 557 3
	setp.neu.f64 	%p1, %fd15, %fd14;
	@%p1 bra 	BB1_2;

	mov.f64 	%fd16, 0d0000000000000000;
	.loc 2 1049 5
	mul.rn.f64 	%fd41, %fd41, %fd16;

BB1_2:
	.loc 3 334 3
	mul.f64 	%fd17, %fd41, 0d3FE45F306DC9C883;
	.loc 2 1225 5
	cvt.rni.s32.f64 	%r16, %fd17;
	.loc 3 334 3
	st.local.u32 	[%rd2], %r16;
	.loc 3 335 3
	cvt.rn.f64.s32 	%fd18, %r16;
	.loc 3 340 3
	neg.f64 	%fd19, %fd18;
	mov.f64 	%fd20, 0d3FF921FB54442D18;
	.loc 2 721 5
	fma.rn.f64 	%fd21, %fd19, %fd20, %fd41;
	mov.f64 	%fd22, 0d3C91A62633145C00;
	.loc 2 721 5
	fma.rn.f64 	%fd23, %fd19, %fd22, %fd21;
	mov.f64 	%fd24, 0d397B839A252049C0;
	.loc 2 721 5
	fma.rn.f64 	%fd42, %fd19, %fd24, %fd23;
	.loc 2 405 5
	abs.f64 	%fd25, %fd41;
	.loc 3 343 3
	setp.leu.f64 	%p2, %fd25, 0d41E0000000000000;
	@%p2 bra 	BB1_4;

	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd4;
	.param .b64 retval0;
	.loc 3 344 5
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd_sin_f64, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd42, [retval0+0];
	}
	// Callseq End 0
	.loc 3 346 3
	ld.local.u32 	%r16, [%rd2];

BB1_4:
	.loc 3 372 3
	shl.b32 	%r6, %r16, 3;
	and.b32  	%r7, %r6, 8;
	.loc 3 375 3
	{
	.reg .b32 temp;
	and.b32	 temp, %r16, 1;
	setp.b32.eq 	 %p3, temp, 1;
	}
	not.pred 	%p4, %p3;
	selp.f64 	 %fd26, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p4;
	.loc 3 376 3
	mul.wide.u32 	%rd7, %r7, 8;
	mov.u64 	%rd8, __cudart_sin_cos_coeffs_sin_f64;
	add.s64 	%rd9, %rd7, %rd8;
	ld.const.f64 	%fd27, [%rd9+8];
	.loc 2 1049 5
	mul.rn.f64 	%fd6, %fd42, %fd42;
	.loc 2 721 5
	fma.rn.f64 	%fd28, %fd26, %fd6, %fd27;
	.loc 3 377 3
	ld.const.f64 	%fd29, [%rd9+16];
	.loc 2 721 5
	fma.rn.f64 	%fd30, %fd28, %fd6, %fd29;
	.loc 3 378 3
	ld.const.f64 	%fd31, [%rd9+24];
	.loc 2 721 5
	fma.rn.f64 	%fd32, %fd30, %fd6, %fd31;
	.loc 3 379 3
	ld.const.f64 	%fd33, [%rd9+32];
	.loc 2 721 5
	fma.rn.f64 	%fd34, %fd32, %fd6, %fd33;
	.loc 3 380 3
	ld.const.f64 	%fd35, [%rd9+40];
	.loc 2 721 5
	fma.rn.f64 	%fd36, %fd34, %fd6, %fd35;
	.loc 3 381 3
	ld.const.f64 	%fd37, [%rd9+48];
	.loc 2 721 5
	fma.rn.f64 	%fd7, %fd36, %fd6, %fd37;
	.loc 2 721 5
	fma.rn.f64 	%fd43, %fd7, %fd42, %fd42;
	.loc 3 383 3
	@%p4 bra 	BB1_6;

	mov.f64 	%fd38, 0d3FF0000000000000;
	.loc 2 721 5
	fma.rn.f64 	%fd43, %fd7, %fd6, %fd38;

BB1_6:
	.loc 3 384 3
	and.b32  	%r14, %r16, 2;
	setp.eq.s32 	%p5, %r14, 0;
	@%p5 bra 	BB1_8;

	mov.f64 	%fd39, 0d0000000000000000;
	mov.f64 	%fd40, 0dBFF0000000000000;
	.loc 2 721 5
	fma.rn.f64 	%fd43, %fd43, %fd40, %fd39;

BB1_8:
	.loc 4 9 1
	mov.f64 	res, %fd43;
	.loc 4 11 2
	ret;
}

